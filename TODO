ToDo List for Slony-I
-----------------------------------------

$Id: TODO,v 1.13 2007-11-22 22:56:21 cbbrowne Exp $

Documentation Improvements
--------------------------------------------

- Removed all support for STORE/DROP TRIGGER commands. Users are
  supposed to use the ALTER TABLE [ENABLE|DISABLE] TRIGGER
  functionality in Postgres from now on.

  There is now mention of this in docs/adminguide/slonyupgrade.sgml;
  need to enhance it further after discussion with Jan Wieck.

Short Term Items
---------------------------

CANCEL SUBSCRIPTION
   <http://lists.slony.info/pipermail/slony1-hackers/2007-May/000011.html>

Improve script that tries to run UPDATE FUNCTIONS across versions to
verify that upgrades work properly.

- Clone Node - use pg_dump/PITR to populate a new subscriber node

  Jan working on this

- UPDATE FUNCTIONS needs to be able to reload version-specific
  functions in v2.0, so that if we do an upgrade via:
    "pg_dump -p $OLDVPORT dbname | psql -p $NEWVERPORT -d dbname"
  we may then run "UPDATE FUNCTIONS" to tell the instance to know
  about the new PostgreSQL version.

  This probably involves refactoring the code that loads the
  version-specific SQL into a function that is called by both STORE
  NODE and UPDATE FUNCTIONS.

- Script to "duplicate node"; create a new node that looks just like
  an existing node, that is, with the same replication sets.

  Overview:
   - Run slony1_extract_schema.sh against the origin node for the sets
     subscribed to; this gives an SQL script.

   - Generate slonik script to do:
     * STORE NODE for new node
     * STORE PATH to get the new node to communicate with the node it's
       duplicating
     * SUBSCRIBE SET for all the relevant sets

- Need to draw some "ducttape" tests into NG tests

   - Need to add a MERGE SET test; should do a pretty mean torture of
     this!

   - Duplicate duct tape test #6 - create 6 nodes:
          - #2 and #3 subscribe to #1
	  - #4 to #3
          - #5 and #6 subscribe to #4

   - Have a test that does a bunch of subtransactions

- Need upgrade path

Longer Term Items
---------------------------

- Add more tests (what???) to test_slony_state script(s).

  e.g. - add a warning if there exist tables with generated PK.

  Arguably, that isn't really a good thing to do; if there is a table
  with column generated via TABLE ADD KEY, then we have the
  undesirable result that there will be an error/warning reported
  every time test_slony_state is run.

  Perhaps there should be a second script that looks for "static"
  problems, so we can leave test_slony_state to look for "dynamic"
  problems.

- Partitioning Support

  Add stored procedures to support adding in subscriptions to empty
  tables; verify emptiness on origin, TRUNCATE on subscribers.  The
  stored proc(s) would be run as part of EXECUTE SCRIPT...

- Use PGXS

- Windows-compatible version of tools/slony1_dump.sh

- Consider pulling the lexer from psql

  http://developer.postgresql.org/cvsweb.cgi/pgsql/src/bin/psql/psqlscan.l?rev=1.21;content-type=text%2Fx-cvsweb-markup

Wishful Thinking
----------------------------

SYNC pipelining

  - the notion here is to open two connections to the source DB, and
    to start running the queries to generate the next LOG cursor while
    the previous request is pushing INSERT/UPDATE/DELETE requests to
    the subscriber.

COPY pipelining

  - the notion here is to try to parallelize the data load at
    SUBSCRIBE time.  Suppose we decide we can process 4 tables at a
    time, we set up 4 threads.  We then iterate thus:

    For each table
       - acquire a thread (waiting as needed)
       - submit COPY TO stdout to the provider, and feed to 
         COPY FROM stdin on the subscriber
       - Submit the REINDEX request on the subscriber

    Even with a fairly small number of threads, we should be able to
    process the whole subscription in as long as it takes to process
    the single largest table.

    This introduces a risk of locking problems not true at present
    (alas) in that, at present, the subscription process is able to
    demand exclusive locks on all tables up front; that is no longer
    possible if the subscriptions are split across multiple tables.
    In addition, the updates will COMMIT across some period of time on
    the subscriber rather than appearing at one instant in time.

    The timing improvement is probably still worthwhile.

    http://lists.slony.info/pipermail/slony1-hackers/2007-April/000000.html

Slonik ALTER TABLE event

    This would permit passing through changes targeted at a single
    table, and require much less extensive locking than traditional
    EXECUTE SCRIPT.

Compress DELETE/UPDATE/INSERT requests

    Some performance benefits could be gotten by compressing sets of
    DELETEs on the same table into a single DELETE statement.  This
    doesn't help the time it takes to fire triggers on the origin, but
    can speed the process of "mass" deleting records on subscribers.

    <http://lists.slony.info/pipermail/slony1-general/2007-July/006249.html>

    Unfortunately, this would complicate the application code, which
    people agreed would be a net loss...

    <http://lists.slony.info/pipermail/slony1-general/2007-July/006267.html>

Data Transformations on Subscriber

    Have an alternative "logtrigger()" scheme which permits creating a
    custom logtrigger function that can read both OLD.* and NEW.* and
    assortedly:

    - Omit columns on a subscriber
    - Omit tuples

SL-Set

- Could it have some policy in it as to preferred failover targets?

Have Tuple Application Work take place on the subscriber

    - When data is pulled from sl_log_*, turn the output into a COPY
      statement

    - Thus, the data is input, in bulk, using a COPY statement

    - Then have triggers on sl_log_* that perform the "distribution"
      work to insert/delete/update data on the subscriber	
