<!-- $Id: bestpractices.sgml,v 1.1 2005-04-20 18:29:00 cbbrowne Exp $ --> 
<sect1 id="bestpractices">
<title> &slony1; <quote>Best Practices</quote> </title>

<para> It is common for managers to have a desire to operate systems
using some available, documented set of <quote>best practices.</quote>
Documenting that sort of thing is essential to ISO 9000, ISO 9001, and
other sorts of organizational certifications. </para>

<para> It is worthwhile to preface a discussion of <quote>best
practices</quote> by mentioning that each organization that uses
&slony1; is unique, and there may be a need for local policies to
reflect unique local operating characteristics.  It is for that reason
that &slony1; does <emphasis>not</emphasis> impose its own policies
for such things as <link linkend="failover"> failover </link>; those
will need to be determined based on the overall shape of your network,
of your set of database servers, and of your usage patterns for those
servers. </para>

<para> There are, however, a number of things that early adopters of
&slony1; have discovered which can at least help to suggest some
policies you might want to consider. </para>

<itemizedlist>

<listitem><para> &slony1; is a complex multi-client, multi-server
system, with the result that there are almost an innumerable set of
places where problems can arise.  </para> 

<para> As a natural result, maintaining a clean environment is really
valuable, as any sort of environmental <quote>messiness</quote> can
either cause unexpected problems or mask the real problem. </para>

<para> Numerous users have reported problems resulting from mismatches
between &slony1; versions, local libraries, and &postgres; libraries.
Details count; you need to be clear on what hosts are running what
versions of what software.
</para>

</listitem>

<listitem><para> Principle: Long running transactions are Evil </para>

<para> The FAQ has an entry on <link linkend="pglistenerfull"> growth
of <envar>pg_listener</envar> </link> which discusses this in a fair
bit of detail; the long and short is that long running transactions
have numerous ill effects.  They are particularly troublesome on an
<quote>origin</quote> node, holding onto locks, preventing vacuums
from taking effect, and the like.</para>
</listitem>

<listitem><para> <link linkend="Failover"> Failover </link> policies
should be planned for ahead of time.  </para>

<para> This may simply involve thinking about what the priority lists
should be of what should fail to what, as opposed to trying to
automate it.  But knowing what to do ahead of time cuts down on the
number of mistakes made.

<para> At Afilias, some internal <citation>The 3AM Unhappy DBA's Guide
to...</citation> guides have been created to provide checklists of
what to do when <quote>unhappy</quote> things happen; this sort of
material is highly specific to the applications running, so you would
need to generate your own such documents.
</para>
</listitem>

<listitem><para> <xref linkend="stmtmoveset"> should be used to allow
preventative maintenance to prevent problems from becoming serious
enough to require <link linkend="failover"> failover </link>. </para>
</listitem>

<listitem><para> <command>VACUUM</command> policy needs to be
carefully defined.</para>

<para> As mentioned above, <quote>long running transactions are
Evil.</quote> <command>VACUUM</command>s are no exception in this.  A
<command>VACUUM</command> on a huge table will open a long-running
transaction with all the known ill effects.</para>
</listitem>

<listitem><para> Running all of the <xref linkend="slon"> daemons on a
central server for each network has proven preferable. </para> 

<para> Each <xref linkend="slon"> should run on a host on the same
local network as the node that it is servicing, as it does a
<emphasis>lot</emphasis> of communications with its database.  </para>

<para> In theory, the <quote>best</quote> speed would come from
running the <xref linkend="slon"> on the database server that it is
servicing. </para>

<para> In practice, having the <xref linkend="slon"> processes strewn
across a dozen servers turns out to be really inconvenient to manage,
as making changes to their configuration requires logging onto a whole
bunch of servers.  In environments where it is necessary to use
<application>sudo</application> for users to switch to application
users, this turns out to be seriously inconvenient.  It turns out to
be <emphasis>much</emphasis> easier to manage to group the <xref
linkend="slon"> processes on one server per local network, so that
<emphasis>one</emphasis> script can start, monitor, terminate, and
otherwise maintain <emphasis>all</emphasis> of the nearby nodes.</para>

<para> That also has the implication that configuration data and
configuration scripts only need to be maintained in one place,
eliminating duplication of configuration efforts.</para>
</listitem>

<listitem><para>The <link linkend="ddlchanges"> Database Schema
Changes </link> section outlines some practices that have been found
useful for handling changes to database schemas. </para></listitem>

<listitem><para> Handling of Primary Keys </para> 

<para> Discussed in the section on <link linkend="definingsets">
Replication Sets, </link> it is <emphasis>ideal</emphasis> if each
replicated table has a true primary key constraint; it is
<emphasis>acceptable</emphasis> to use a <quote>candidate primary key.</quote></para>

<para> It is <emphasis>not recommended</emphasis> that a
&slony1;-defined key be used to introduce a candidate primary key, as
this introduces the possibility that updates to this table can fail
due to the introduced unique index, which means that &slony1; has
introduced a new failure mode for your application.</para>
</listitem>

<listitem><para> <link linkend="definesets"> Grouping tables into sets
</link> suggests strategies for determining how to group tables and
sequences into replication sets. </para> </listitem>

<listitem><para> It should be obvious that actions that can delete a
lot of data should be taken with great care; the section on <link
linkend="dropthings"> Dropping things from &slony1; Replication</link>
discusses the different sorts of <quote>deletion</quote> that &slony1;
supports.  </para> </listitem>

<listitem><para> listen path management </para> </listitem>

<listitem><para> path configuration </para> </listitem>

<listitem><para> configuring slon </para> </listitem>

<listitem><para> when subscribing nodes </para> </listitem>

<listitem><para> managing use of slonik </para> </listitem>

</itemizedlist>

</sect1>
<!-- Keep this comment at the end of the file
Local variables:
mode:sgml
sgml-omittag:nil
sgml-shorttag:t
sgml-minimize-attributes:nil
sgml-always-quote-attributes:t
sgml-indent-step:1
sgml-indent-data:t
sgml-parent-document:"book.sgml"
sgml-exposed-tags:nil
sgml-local-catalogs:("/usr/lib/sgml/catalog")
sgml-local-ecat-files:nil
End:
-->
